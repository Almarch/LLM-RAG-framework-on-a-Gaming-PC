
services:
  llm:
    build: ./services/llm/
    volumes:
      - ./services/llm/model:/model
    ports:
      - 7777:80
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  encoder:
    build: ./services/encoder/
    volumes:
      - ./services/encoder/model:/model

  ocr:
    build: ./services/ocr/

  tokenizer:
    build: ./services/tokenizer/

  weaviate:
    image: semitechnologies/weaviate:1.21.2
    restart: always
    depends_on:
      - encoder
    environment:
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: 'text2vec-transformers'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      TRANSFORMERS_INFERENCE_API: 'http://encoder:80'
    volumes:
      - ./services/weaviate/data:/var/lib/weaviate

  notebook:
    build: ./services/jupyter/
    volumes:
      - ./services/jupyter/notebook:/project
    depends_on:
      - llm
      - encoder
      - weaviate
      - ocr
      - tokenizer
    ports:
      - 8888:8888

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: always
    depends_on:
      - llm
    ports:
      - 80:3000
    environment:
      - OLLAMA_BASE_URL=http://llm:80
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
    volumes:
      - ./services/open-webui/data:/app/backend/data
